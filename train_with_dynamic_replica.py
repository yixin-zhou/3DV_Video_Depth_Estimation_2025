#!/usr/bin/env python3
"""
ä½¿ç”¨ DynamicReplicaDataset è®­ç»ƒæ¨¡å‹çš„ç¤ºä¾‹è„šæœ¬

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†å¦‚ä½•åœ¨è®­ç»ƒä¸­ä½¿ç”¨ DynamicReplicaDataset
"""

import os
import sys
import argparse
import torch
from torch.utils.data import DataLoader

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
root = os.path.dirname(__file__)
sys.path.insert(0, root)

from datasets_for_ourstereo.dynamic_replica_dataset import DynamicReplicaDataset
from datasets_for_ourstereo.datasets import VideoSintelDataset


def create_dynamic_replica_dataloader(args, is_train=True):
    """åˆ›å»º DynamicReplicaDataset æ•°æ®åŠ è½½å™¨
    
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        is_train: æ˜¯å¦ä¸ºè®­ç»ƒæ•°æ®é›†
        
    Returns:
        torch.utils.data.DataLoader: æ•°æ®åŠ è½½å™¨
    """
    # è®¾ç½®æ•°æ®å¢å¼ºå‚æ•° (ä»…å¯¹è®­ç»ƒé›†åº”ç”¨å¢å¼º)
    aug_params = {
        'brightness': 0.3,
        'contrast': 0.3,
        'saturation': [0.8, 1.2],
        'hue': 0.5/3.14,
        'gamma_params': [0.9, 1.3, 1.0, 1.2]
    } if is_train else {}
    
    # æ•°æ®é›†è·¯å¾„
    base_dir = args.dynamic_replica_path
    
    print(f"{'è®­ç»ƒ' if is_train else 'éªŒè¯'} æ•°æ®é›†è·¯å¾„: {base_dir}")
    print(f"è£å‰ªå°ºå¯¸: {args.crop_size}")
    
    # åˆ›å»º DynamicReplica æ•°æ®é›†
    dataset = DynamicReplicaDataset(
        base_dir=base_dir,
        aug_params=aug_params,
        crop_size=args.crop_size,
        preload_data=True,
        max_sequences=args.max_sequences if hasattr(args, 'max_sequences') else None,
        focal_length=args.focal_length if hasattr(args, 'focal_length') else 1050.0,
        baseline=args.baseline if hasattr(args, 'baseline') else 0.54
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    loader = DataLoader(
        dataset, 
        batch_size=args.batch_size,
        shuffle=is_train,
        num_workers=args.num_workers,
        drop_last=is_train,
        pin_memory=True,
        persistent_workers=args.num_workers > 0
    )
    
    return loader


def create_mixed_dataloader(args, is_train=True):
    """åˆ›å»ºæ··åˆæ•°æ®é›† (Sintel + DynamicReplica) çš„æ•°æ®åŠ è½½å™¨
    
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        is_train: æ˜¯å¦ä¸ºè®­ç»ƒæ•°æ®é›†
        
    Returns:
        torch.utils.data.DataLoader: æ•°æ®åŠ è½½å™¨
    """
    from torch.utils.data import ConcatDataset
    
    # è®¾ç½®æ•°æ®å¢å¼ºå‚æ•°
    aug_params = {
        'brightness': 0.3,
        'contrast': 0.3,
        'saturation': [0.8, 1.2],
        'hue': 0.5/3.14,
        'gamma_params': [0.9, 1.3, 1.0, 1.2]
    } if is_train else {}
    
    datasets = []
    
    # æ·»åŠ  Sintel æ•°æ®é›†
    if hasattr(args, 'sintel_path') and args.sintel_path:
        print(f"æ·»åŠ  Sintel æ•°æ®é›†: {args.sintel_path}")
        sintel_dataset = VideoSintelDataset(
            dstype='clean',
            base_dir=args.sintel_path,
            aug_params=aug_params,
            crop_size=args.crop_size
        )
        datasets.append(sintel_dataset)
    
    # æ·»åŠ  DynamicReplica æ•°æ®é›†
    if hasattr(args, 'dynamic_replica_path') and args.dynamic_replica_path:
        print(f"æ·»åŠ  DynamicReplica æ•°æ®é›†: {args.dynamic_replica_path}")
        replica_dataset = DynamicReplicaDataset(
            base_dir=args.dynamic_replica_path,
            aug_params=aug_params,
            crop_size=args.crop_size,
            max_sequences=args.max_sequences if hasattr(args, 'max_sequences') else None
        )
        datasets.append(replica_dataset)
    
    if not datasets:
        raise ValueError("è‡³å°‘éœ€è¦æŒ‡å®šä¸€ä¸ªæ•°æ®é›†è·¯å¾„")
    
    # åˆå¹¶æ•°æ®é›†
    if len(datasets) == 1:
        combined_dataset = datasets[0]
    else:
        combined_dataset = ConcatDataset(datasets)
        print(f"åˆå¹¶æ•°æ®é›†ï¼Œæ€»æ ·æœ¬æ•°: {len(combined_dataset)}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    loader = DataLoader(
        combined_dataset, 
        batch_size=args.batch_size,
        shuffle=is_train,
        num_workers=args.num_workers,
        drop_last=is_train,
        pin_memory=True,
        persistent_workers=args.num_workers > 0
    )
    
    return loader


def test_dataloader(dataloader, name="æ•°æ®åŠ è½½å™¨"):
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
    print(f"\næµ‹è¯• {name}...")
    print(f"æ•°æ®é›†å¤§å°: {len(dataloader.dataset)}")
    print(f"æ‰¹æ¬¡æ•°é‡: {len(dataloader)}")
    
    # æµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
    for batch_idx, (left_seq, right_seq, disp_seq) in enumerate(dataloader):
        print(f"æ‰¹æ¬¡ {batch_idx}:")
        print(f"  - å·¦å›¾åƒåºåˆ—: {left_seq.shape}, ç±»å‹: {left_seq.dtype}")
        print(f"  - å³å›¾åƒåºåˆ—: {right_seq.shape}, ç±»å‹: {right_seq.dtype}")
        print(f"  - è§†å·®åºåˆ—: {disp_seq.shape}, ç±»å‹: {disp_seq.dtype}")
        print(f"  - å·¦å›¾åƒå€¼èŒƒå›´: [{left_seq.min():.3f}, {left_seq.max():.3f}]")
        print(f"  - å³å›¾åƒå€¼èŒƒå›´: [{right_seq.min():.3f}, {right_seq.max():.3f}]")
        print(f"  - è§†å·®å€¼èŒƒå›´: [{disp_seq.min():.3f}, {disp_seq.max():.3f}]")
        
        if batch_idx >= 2:  # åªæµ‹è¯•å‰3ä¸ªæ‰¹æ¬¡
            break
    
    print(f"âœ… {name} æµ‹è¯•å®Œæˆ")


def main():
    parser = argparse.ArgumentParser(description="DynamicReplicaDataset è®­ç»ƒç¤ºä¾‹")
    
    # æ•°æ®é›†è·¯å¾„
    parser.add_argument("--dynamic_replica_path", type=str, 
                       default="/home/shizl/3DV_Video_Depth_Estimation_2025/data/extracted",
                       help="DynamicReplica æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--sintel_path", type=str, 
                       default="/home/shizl/3DV_Video_Depth_Estimation_2025/data/MPI-Sintel-stereo-training-20150305/training",
                       help="Sintel æ•°æ®é›†è·¯å¾„")
    
    # æ•°æ®å‚æ•°
    parser.add_argument("--crop_size", nargs=2, type=int, default=[256, 256], help="è£å‰ªå°ºå¯¸ [H, W]")
    parser.add_argument("--batch_size", type=int, default=2, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--num_workers", type=int, default=4, help="æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°")
    parser.add_argument("--max_sequences", type=int, default=None, help="é™åˆ¶åºåˆ—æ•°é‡ (ç”¨äºè°ƒè¯•)")
    
    # DynamicReplica ç‰¹å®šå‚æ•°
    parser.add_argument("--focal_length", type=float, default=1050.0, help="ç›¸æœºç„¦è·")
    parser.add_argument("--baseline", type=float, default=0.54, help="åŒç›®åŸºçº¿è·ç¦»")
    
    # æµ‹è¯•é€‰é¡¹
    parser.add_argument("--test_mode", choices=["dynamic_replica", "sintel", "mixed"], 
                       default="dynamic_replica", help="æµ‹è¯•æ¨¡å¼")
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("DynamicReplicaDataset è®­ç»ƒç¤ºä¾‹")
    print("=" * 60)
    print(f"æµ‹è¯•æ¨¡å¼: {args.test_mode}")
    print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"è£å‰ªå°ºå¯¸: {args.crop_size}")
    print(f"å·¥ä½œè¿›ç¨‹æ•°: {args.num_workers}")
    
    try:
        if args.test_mode == "dynamic_replica":
            # æµ‹è¯• DynamicReplica æ•°æ®é›†
            train_loader = create_dynamic_replica_dataloader(args, is_train=True)
            test_dataloader(train_loader, "DynamicReplica è®­ç»ƒæ•°æ®åŠ è½½å™¨")
            
        elif args.test_mode == "sintel":
            # æµ‹è¯• Sintel æ•°æ®é›† (ä½œä¸ºå¯¹æ¯”)
            from FoundationStereo.Train_our_model import fetch_dataloader
            train_loader = fetch_dataloader(args, is_train=True)
            test_dataloader(train_loader, "Sintel è®­ç»ƒæ•°æ®åŠ è½½å™¨")
            
        elif args.test_mode == "mixed":
            # æµ‹è¯•æ··åˆæ•°æ®é›†
            train_loader = create_mixed_dataloader(args, is_train=True)
            test_dataloader(train_loader, "æ··åˆè®­ç»ƒæ•°æ®åŠ è½½å™¨")
        
        print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
